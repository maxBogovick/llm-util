# LLM Prompt - {{ ctx.preset.name }}

**Part {{ ctx.chunk_index }}/{{ ctx.total_chunks }}**

---

## Preset Information

- **Preset**: {{ ctx.preset.name }} ({{ ctx.preset.id }})
- **Description**: {{ ctx.preset.description }}
- **Suggested Model**: {{ ctx.preset.suggested_model }}
- **Max Tokens**: {{ ctx.preset.max_tokens_hint }}
- **Temperature**: {{ ctx.preset.temperature_hint }}

---

## System Prompt

{{ ctx.preset.system_prompt }}

---

## User Prompt

{{ ctx.preset.user_prompt_template }}

---

## Project Context

> Generated: {{ ctx.metadata.generated_at }}
>
> Files in this chunk: {{ ctx.chunk_files }}
>
> Total tokens: ~{{ ctx.total_tokens }}

---

## Codebase Content

{% for file in ctx.files %}
### ðŸ“„ `{{ file.relative_path }}`

{% if file.is_binary -%}
*[Binary file - {{ file.token_count }} bytes]*
{% else -%}
**Tokens:** ~{{ file.token_count }} | **Lines:** {{ file.lines | default(value=0) }}

```{% set ext = file.relative_path | split(pat=".") | last %}{% if ext == "rs" %}rust{% elif ext == "py" %}python{% elif ext == "js" %}javascript{% elif ext == "ts" %}typescript{% elif ext == "toml" %}toml{% elif ext == "json" %}json{% elif ext == "yaml" or ext == "yml" %}yaml{% elif ext == "md" %}markdown{% elif ext == "sh" %}bash{% elif ext == "c" or ext == "h" %}c{% elif ext == "cpp" or ext == "hpp" %}cpp{% elif ext == "go" %}go{% elif ext == "java" %}java{% elif ext == "rb" %}ruby{% elif ext == "php" %}php{% elif ext == "html" %}html{% elif ext == "css" %}css{% elif ext == "xml" %}xml{% else %}{% endif %}
{{ file.content }}
```
{% endif %}

---

{% endfor %}

<!-- End of chunk {{ ctx.chunk_index }}/{{ ctx.total_chunks }} -->

---

## Instructions for LLM

Based on the **{{ ctx.preset.name }}** preset, please analyze the provided codebase and deliver results according to the specified system prompt and user prompt template above.